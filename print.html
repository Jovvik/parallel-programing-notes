<!DOCTYPE HTML>
<html lang="ru" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Конспект по параллельному программированию</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="lec_1.1.html"><strong aria-hidden="true">1.</strong> Лекция 1.1. Введение и мотивация</a></li><li class="chapter-item expanded "><a href="lec_1.2.html"><strong aria-hidden="true">2.</strong> Лекция 1.2. Lock-free stack и Michael-Scott queue</a></li><li class="chapter-item expanded "><a href="lec_2.1.html"><strong aria-hidden="true">3.</strong> Лекция 2.1. Определения и Формализм</a></li><li class="chapter-item expanded "><a href="lec_2.2.html"><strong aria-hidden="true">4.</strong> Лекция 2.2. Построение атомарных объектов и блокировки</a></li><li class="chapter-item expanded "><a href="lec_3.1.html"><strong aria-hidden="true">5.</strong> Лекция 3.1. Практические построения на списках</a></li><li class="chapter-item expanded "><a href="lec_3.2.html"><strong aria-hidden="true">6.</strong> Лекция 3.2. Relaxed Algorithms</a></li><li class="chapter-item expanded "><a href="lec_4.1.html"><strong aria-hidden="true">7.</strong> Лекция 4.1. Алгоритмы без блокировок: Построения на регистрах</a></li><li class="chapter-item expanded "><a href="lec_4.2.html"><strong aria-hidden="true">8.</strong> Лекция 4.2. Алгоритмы без блокировок: Консенсус</a></li><li class="chapter-item expanded "><a href="lec_5.html"><strong aria-hidden="true">9.</strong> Лекция 5. JMM</a></li><li class="chapter-item expanded "><a href="lec_6.html"><strong aria-hidden="true">10.</strong> Лекция 6. FAA-Based Queue &amp; Flat Combining</a></li><li class="chapter-item expanded "><a href="lec_7.1.html"><strong aria-hidden="true">11.</strong> Лекция 7.1. Мониторы и ожидание</a></li><li class="chapter-item expanded "><a href="lec_7.2.html"><strong aria-hidden="true">12.</strong> Лекция 7.2. Сложные блокировки</a></li><li class="chapter-item expanded "><a href="lec_8.html"><strong aria-hidden="true">13.</strong> Лекция 8. Многопоточные хеш-таблицы</a></li><li class="chapter-item expanded "><a href="lec_9.html"><strong aria-hidden="true">14.</strong> Лекция 9. Dual Data Structures</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Конспект по параллельному программированию</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="Лекция-11-Введение-и-мотивация"><a class="header" href="#Лекция-11-Введение-и-мотивация">Лекция 1.1. Введение и мотивация</a></h1>
<hr />
<h3 id="Закон-Мура-и-the-free-lunch-is-over"><a class="header" href="#Закон-Мура-и-the-free-lunch-is-over">Закон Мура и «The free lunch is over?»</a></h3>
<p>Количество транзисторов удваивается каждые два года, частота ядра раньше также росла экспоненциально, но в двухтысячных перестала. Производительность отдельно взятого ядра с тех пор стала расти медленнее, стали ускоряться за счёт большего числа ядер.</p>
<h3 id="Закон-Амдала"><a class="header" href="#Закон-Амдала">Закон Амдала</a></h3>
<p><code>N</code> – число потоков, <code>P</code> – доля параллельного кода, <code>S</code> - ускорение кода</p>
<p>$$
S = \frac{Time\ on\ 1\ core}{Time\ on\ N\ cores} = \frac{1}{1 - P + \frac{P}{N}}
$$</p>
<p>при \(N \to \infty \) максимальное ускорение кода \( \frac{1}{1 - P} \)</p>
<h3 id="Параллелизм-на-уровне-инструкций-ilp"><a class="header" href="#Параллелизм-на-уровне-инструкций-ilp">Параллелизм на уровне инструкций (ILP)</a></h3>
<p>Нет зависимости по данным, (1) и (2) можно выполнить параллельно.</p>
<pre><code class="language-java">e = a + b // 1
f = c + d // 2
</code></pre>
<p>Способы использования ILP:</p>
<ul>
<li>Конвейер</li>
<li>Суперскалярное исполнение
<ul>
<li>Внеочередное исполнение</li>
<li>Переименование регистров</li>
<li>Спекулятивное исполнение</li>
<li>Предсказание переходов</li>
</ul>
</li>
<li>Длинное машинное слово (VLIW)</li>
<li>Векторизация (SIMD)</li>
</ul>
<h2 id="Примеры-архитектуры-многопроцессорных-компьютеров"><a class="header" href="#Примеры-архитектуры-многопроцессорных-компьютеров">Примеры архитектуры многопроцессорных компьютеров</a></h2>
<h3 id="Симметричная-мультипроцессорность-smp"><a class="header" href="#Симметричная-мультипроцессорность-smp">Симметричная мультипроцессорность (SMP)</a></h3>
<p><img src="img/1_smp.jpg" alt="smp" /></p>
<h3 id="Ассиметричный-доступ-к-памяти-numa"><a class="header" href="#Ассиметричный-доступ-к-памяти-numa">Ассиметричный доступ к памяти (NUMA)</a></h3>
<p><img src="img/1_numa.jpg" alt="numa" /></p>
<p>Виды многопоточных систем:</p>
<ul>
<li>Одновременная многопоточность (SMT) – в каждый данный момент может исполняться несколько потоков.</li>
<li>Временная многопоточность (TMT) – в каждый данный момент может исполняться только один поток.</li>
</ul>
<h2 id="Операционные-системы"><a class="header" href="#Операционные-системы">Операционные системы</a></h2>
<h3 id="Типы-операционных-систем"><a class="header" href="#Типы-операционных-систем">Типы операционных систем</a></h3>
<ul>
<li>Однозадачные</li>
<li>Система с пакетными заданиями (batch processing)</li>
<li>Многозадачные / с разделением времени (time-sharing)
<ul>
<li>Кооперативная многозадачность (cooperative multitasking)</li>
<li>Вытесняющая многозадачность (preemptive multitasking)</li>
</ul>
</li>
</ul>
<h3 id="Основные-понятия-в-современных-ОС"><a class="header" href="#Основные-понятия-в-современных-ОС">Основные понятия в современных ОС</a></h3>
<ul>
<li>Процесс – владеет памятью и ресурсами. ОС создаёт иллюзию того, что каждый процесс имеет абстрактную вычислительную систему в своём полном распоряжении.</li>
<li>Поток – контекст исполнения внутри процесса. В одном процессе может быть несколько потоков, все потоки работают с общей памятью процесса.</li>
<li>В научных работах исторически сложилось называть потоки процессами и использовать большие буквы: <code>P</code>, <code>Q</code>, ...</li>
</ul>
<p>В теории мы их будем смешивать, хоть это и некорректно</p>
<h2 id="Формализм"><a class="header" href="#Формализм">Формализм</a></h2>
<p>Нужна формальная модель параллельных вычислений для того, чтобы использовать её в доказательствах корректности алгоритмов, а также невозможности построения тех или иных алгоритмов и минимально-необходимые требования для тех или иных алгоритмов.</p>
<p>А ещё формальная модель нужна для формализации отношений между прикладным программистом и разработчиком компилятора и системы исполнения кода.</p>
<h3 id="Модели-программирования"><a class="header" href="#Модели-программирования">Модели программирования</a></h3>
<ul>
<li>«Классическое» однопоточное / однозадачное (можем использовать ресурсы многоядерной системы только запустив множества разных, независимых задач)</li>
<li>Многозадачное программирование (можем использовать ресурсы многоядерной системы в рамках решения одной задачи)
<ul>
<li>Модель с общей памятью (рассматриваем в рамках этого курса)</li>
<li>Модель с передачей сообщений (распределенное программирование)</li>
</ul>
</li>
</ul>
<h3 id="Общие-объекты"><a class="header" href="#Общие-объекты">Общие объекты</a></h3>
<p>Потоки выполняют действия над общими, разделяемыми объектами. В этой модели не важны операции внутри потоков: вычисления, обновления регистров процессора, обновления регистров потока.</p>
<h4 id="Общие-переменные"><a class="header" href="#Общие-переменные">Общие переменные</a></h4>
<p>Это простейший тип общего объекта, базовый строительный блок для многопоточного алгоритма. У общих переменных есть операции чтения и записи, а также значение определенного типа.</p>
<p><strong>Модель с общими переменными</strong> – это хорошая абстракция современных многопроцессорных систем и многопоточных ОС. На практике, это общая память процесса, которая доступна для чтения и записи всем потокам, исполняемым в данном процессе.</p>
<p><em>В теоретических трудах общие переменные часто называют регистрами.</em></p>
<p>Многопоточные программы в общем случае недетерминированы, в отличие от однопоточных программ. Поэтому мы говорим, что <strong>программа А имеет свойство Р</strong>, если программа А имеет свойство Р <strong>при любом исполнении</strong>.</p>
<h3 id="Моделирование-работы-программы"><a class="header" href="#Моделирование-работы-программы">Моделирование работы программы</a></h3>
<p>Рассмотрим модель чередования, где исполнение потоков чередуется в произвольном порядке. Тогда у нижеуказанной программы есть три исхода, она не может завершиться в состоянии <code>{0, 0}</code>.</p>
<pre><code class="language-java">@JCStressTest
@State
@Outcome(id = &quot;0, 1&quot;, expect = Expect.ACCEPTABLE)
@Outcome(id = &quot;1, 0&quot;, expect = Expect.ACCEPTABLE)
@Outcome(id = &quot;1, 1&quot;, expect = Expect.ACCEPTABLE)
public class SimpleTest1 {
    int x;
    int y;
    
    @Actor 
    public void threadP(IntResult r) {
        x = 1;
        r.r2 = y;
    }
    
    @Actor 
    public void threadQ(IntResult r) {
        y = 1;
        r.r1 = x;
    }
}
</code></pre>
<p>Однако на практике у нас всё сломалось, все четыре результата возможны, при этом <code>{1, 1}</code> реже всех. Почему? Потому что тестировали на TSO (Total Store Order) модели памяти, где операции записи кладутся в буфер, и чтение в некоторых случаях было выполнено раньше, чем запись «дошла» до памяти.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-12-lock-free-stack-и-michael-scott-queue"><a class="header" href="#Лекция-12-lock-free-stack-и-michael-scott-queue">Лекция 1.2. Lock-free stack и Michael-Scott queue</a></h1>
<h2 id="План-лекции"><a class="header" href="#План-лекции">План лекции</a></h2>
<ol>
<li>Неблокирующиеся алгоритмы</li>
<li>Lock-free Treiber Stack</li>
<li>Michael-Scott Queue</li>
</ol>
<h2 id="mutual-exclusion"><a class="header" href="#mutual-exclusion">Mutual exclusion</a></h2>
<p>Aka <code>mutex</code> или <code>lock</code>, только один поток может держать блокировку.</p>
<h3 id="atomic-counter"><a class="header" href="#atomic-counter">Atomic counter</a></h3>
<pre><code class="language-kotlin">val l = Lock()
var counter = 0

fun incAndGet(): Int {
    l.lock()
    try {
    return ++counter
    } finally {
        l.unlock()
    }
}
</code></pre>
<p>Эта блокировка грубая. Нет гарантии прогресса в том случае, если CPU отберут, потому что все другие потоки будут ждать наш поток.</p>
<h2 id="lock-freedom"><a class="header" href="#lock-freedom">Lock-freedom</a></h2>
<p>Гарантирует прогресс в системе. Базовая операция (реализована в железе): <code>CAS (Compare-And-Set)</code> – <code>CAS(p, old, new)</code> атомарно проверяет, что значение по адресу <code>p</code> атомарно совпадает с <code>old</code> и заменяет его на <code>new</code>.</p>
<h3 id="counter"><a class="header" href="#counter">Counter</a></h3>
<pre><code class="language-kotlin">fun getAndInc(): Int {
    while (true) {
        cur := c
        if CAS(&amp;c, cur, cur + 1) {
            return c
        }
    }
}
</code></pre>
<h3 id="stack"><a class="header" href="#stack">Stack</a></h3>
<pre><code class="language-kotlin">fun pop(): Int {
    head := H
    while (true) {
        if CAS(&amp;H, head, head?.Next) {
                if head == null: return null
                return head.Value
            }
        }
    }
}

fun push(x: Int) {
    while (true) {  
        head := H
        newHead := Node {Value: x, Next: head}
        if CAS(&amp;H, head, newHead): return
    }
}

fun top(): Int? {
    head := H
    return head?.Value
}
</code></pre>
<p><strong>Последовательная согласованность (Sequential consistency)</strong> – это такое последовательное исполнение, которое учитывает порядок внутри потоков, но не учитывает синхронизацию между потоками.</p>
<h3 id="elimination-for-stack"><a class="header" href="#elimination-for-stack">Elimination for Stack</a></h3>
<p>Оптимизация следующая: заведём дополнительный массив фиксированного размера, <code>push</code> сначала пойдёт в его рандомную ячейку (или рядом, если та была уже занята), а <code>pop</code> смотрит несколько рядом стоящих ячеек и ищет занятую. Если операция дождалась (<code>push</code> – <code>pop</code>'а, <code>pop</code> – нового элемента), то всё хорошо, иначе идём в стек и действуем по выше описанному алгоритму.</p>
<p>Таким образом, <code>push</code> и <code>pop</code> могут встретиться, поменяться данными и не дергать стек.</p>
<h3 id="queue"><a class="header" href="#queue">Queue</a></h3>
<p>Операция добавления элемента должна переписать <code>Next</code> у <code>Tail</code> и подвинуть <code>Tail</code> на последний элемент. Если мы перепишем <code>Next</code>, но не успеем подвинуть <code>Tail</code> (какой-то другой поток тоже начал писать) всё сломается.
<strong>Helping</strong>: пусть если поток хочет положить элемент в конец очереди, а у последнего элемента уже есть <code>Next</code>, он просто поможет подвинуть <code>Tail</code> на элемент вперёд и опять попытается добавить свой элемент уже в следующей итерации. Тогда при добавлении элемента и передвижении <code>Tail</code> его <code>CAS</code> для передвижения <code>Tail</code> не пройдёт – хвост уже перенесли.</p>
<pre><code class="language-kotlin">fun enqueue (x: int) {
    newTail := Node { Value = x, N = null}
    while (true) { // CAS loop
        tail := T
        if CAS(&amp;tail.N, null, newTail) {
            // 'newTail' just added, move the tail forward
            CAS (&amp;T, tail, newTail)
            return 
        } else {
            // help other enqueue operations
            CAS(&amp;T, tail, tail.N)
        }
    }
}
</code></pre>
<p>Если убрать ветку <code>else</code>, то алгоритм станет блокирующимся -- новые потоки будут ждать <code>CAS(&amp;T ...)</code>.</p>
<p>Удаление реализуется так же, как в стеке.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-21-Определения-и-Формализм"><a class="header" href="#Лекция-21-Определения-и-Формализм">Лекция 2.1. Определения и Формализм</a></h1>
<h2 id="Физическая-реальность"><a class="header" href="#Физическая-реальность">Физическая реальность</a></h2>
<p>Как мы узнали на прошлой лекции, модель чередования фундаментально ошибочна — она не предполагает реально параллельное исполнение. Кроме того, в реальном мире невозможно синхронизироваться — за один такт свет не успеет физически дойти от ядра до ядра.</p>
<p>На физических событиях в целом нельзя построить отношение полного порядка.</p>
<h2 id="Модель-произошло-до"><a class="header" href="#Модель-произошло-до">Модель &quot;произошло до&quot;</a></h2>
<p><strong>Исполнение</strong> системы это пара \((H, \to_H)\) (history)</p>
<ul>
<li>\(H\) - множество базовых операций \(e, f, g \dots\) (чтение и запись памяти)</li>
<li>\(\to_H\) - частичный (транзитивный, антирефлексивный, ассиметричный) порядок на операциях, называемый &quot;произошло до в исполнении \(H\)&quot;</li>
</ul>
<p>Идейно мы в этой модели поддерживаем параллелизм, т.к. нет требования полного порядка.</p>
<p>Операции \(e\) и \(f\) параллельны, если \(e \not\to f \operatorname{\&amp;} f \not\to e\), это обозначается \(e \parallel f\)</p>
<p>Сложная операция \(e\) состоит из двух простых событий: \(inv(e)\) и \(res(e)\) (invoke, result).</p>
<p>Простые события <strong>полностью</strong> упорядочены отношением \(&lt;_H\). По определению \(e \to_H f\) тогда и только тогда, когда \(res(e) &lt;_H inv(f)\). Так как порядок полный, у нас есть глобальное время.</p>
<p><img src="img/time.png" alt="Time" /></p>
<p><strong>Система</strong> — набор всех возможных исполнений системы.</p>
<p>На практике отношение &quot;произошло до&quot; предоставляется моделью памяти языка. (<code>std::atomic</code>, <code>volatile</code>, создание и <code>join</code> потоков, либы)</p>
<p><img src="img/operation.png" alt="Operation" /></p>
<h3 id="Последовательное-исполнение"><a class="header" href="#Последовательное-исполнение">Последовательное исполнение</a></h3>
<p>Исполнение системы <strong>последовательно</strong>, если все операции линейно упорядочены отношением \(\to\), то есть:
$$\forall e, f \in H : (e = f) \lor (e \to f) \lor (f \to e)$$</p>
<h2 id="Конфликты-и-гонки-данных"><a class="header" href="#Конфликты-и-гонки-данных">Конфликты и гонки данных</a></h2>
<p>Если одна из двух операций над одной и той же переменной - запись, то эта пара операций называется <strong>конфликутующей</strong>, они не коммутируют.</p>
<p>Если при конкретном исполнении две конфликтующие операции произошли параллельно, то произошла <strong>гонка данных</strong>.</p>
<p>Программа называется <strong>корректно синхронизированной</strong>, если при любом допустимом (по спеку языка) исполнении нет <strong>гонок данных</strong>.</p>
<h2 id="Правильное-исполнение"><a class="header" href="#Правильное-исполнение">Правильное исполнение</a></h2>
<p><strong>Сужение</strong> исполнения \(H\) на поток \(P\) это исполнение, где остались только операции, происходящие в потоке \(P\). Обозначается \(H\mid_P\).</p>
<p>Исполнение <strong>правильное</strong>, если его сужение на каждый поток является <strong>последовательным</strong>. Мы рассматриваем только такие исполнения.</p>
<p>В реальности современные процессоры в силу конвейерности не последовательны в рамках одного ядра, но это спрятано от юзера. </p>
<p><strong>Программный порядок (program order)</strong> - сужение отношения &quot;произошло до&quot; на отдельные потоки.</p>
<p>Сужение истории \(H\) на объект \(x\) - множество операций над \(x\), обозначается \(H\mid_x\)</p>
<h2 id="Допустимое-исполнение"><a class="header" href="#Допустимое-исполнение">Допустимое исполнение</a></h2>
<p>Последователньая спецификация объекта проверяется на любом последовательном сужении истории на объект. Если она выполнена, то исполнение <strong>допустимо</strong>.</p>
<p>Но какое параллельное исполнение допустимо? Если получится сопоставить допустимое последовательно исполнение, то наше параллельное исполнение будем считать допустимым.</p>
<p>Однако есть разные варианты сопоставления, они называются <strong>условия согласованности</strong>. Есть базовое требование к условиям - корректные последовательные программы должны быть согласованы при их однопоточном исполнении.</p>
<p>Нас интересуют только два условия: последовательная согласованность (sequential consistency) и линеаризуемость.</p>
<h3 id="Последовательная-согласованность"><a class="header" href="#Последовательная-согласованность">Последовательная согласованность</a></h3>
<p>Исполнение <strong>последовательно согласованно</strong>, если можно сопоставить эквивалентное ему допустимое последовательное исполнение, которое сохраняет <strong>программный порядок</strong> – порядок операций на каждом потоке.</p>
<p>Есть одна проблема - последовательно согласованное исполнение на нескольких объектах по отдельности не последовательно согласовано в целом.</p>
<p><img src="img/seq_cons.png" alt="Seq" /></p>
<p>Таким образом, нет смысла говорить, что отдельный объект последовательно согласован; надо говорить про систему в целом. Например, JMM последовательно согласована.</p>
<h3 id="Линеаризуемость"><a class="header" href="#Линеаризуемость">Линеаризуемость</a></h3>
<p>Исполнение <strong>линеаризуемо</strong>, если можно сопоставить эквивалентное ему допустимое последовательное исполнение, которое сохраняет порядок &quot;произошло до&quot;.</p>
<p>Это самый строгий критерий.</p>
<p><img src="img/nonlin.png" alt="Nonlin" /></p>
<p><em>Теорема:</em> исполнение линеаризуемо тогда и только тогда, когда линеаризуемо исполнение на каждом объекте по отдельности.</p>
<p><em>Доказательство:</em></p>
<ul>
<li><em>Тогда:</em> очевидно.</li>
<li><em>Только тогда:</em> Объединим линеаризацию на каждом объекте \(\to_x\) и исходное \(\to_H\). Транзитивно замкнём полученное отношение. Докажем от противного, что замыкание ациклично.
<img src="img/proof.png" alt="Proof" /></li>
</ul>
<p>Операции над линеаризуемыми объектами называются <strong>атомарными</strong>.</p>
<h4 id="Линеаризуемость-в-глобальном-времени"><a class="header" href="#Линеаризуемость-в-глобальном-времени">Линеаризуемость в глобальном времени</a></h4>
<p>В глобальном времени исполнение линеаризуемо тогда и только тогда, когда можно выбрать точки линеаризации \(e\) такие, что \(t_{inv}(e) &lt; t(e) &lt; t_{res}(e)\)</p>
<p>Исполнение системы с операциями над линеаризуемыми объектами можно анализировать в модели чередования.</p>
<h3 id="В-jmm"><a class="header" href="#В-jmm">В JMM</a></h3>
<p>Операции над <code>volatile</code> полями линеаризуемы, а над не <code>volatile</code> полями нарушена даже последовательная согласованность (без синхронизации). Если же программа корректно синхронизирована, то есть нет гонок, то JMM гарантирует последовательно согласованное исполнение даже не над <code>volatile</code> переменными.</p>
<p>В реальности компилятор вставляет инструкцию <code>mfence</code>, который сбрасывает буфер записи.</p>
<p><code>volatile</code> это медленно.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-22-Построение-атомарных-объектов-и-блокировки"><a class="header" href="#Лекция-22-Построение-атомарных-объектов-и-блокировки">Лекция 2.2. Построение атомарных объектов и блокировки</a></h1>
<p><strong>Декомпозиция исполнения</strong> это пятерка \(H, G, \to_G, inv, res\), где </p>
<ul>
<li>\(H\) это множество операций, \(\forall e \in H : e \subset G\)</li>
<li>\(G\) это множество событий</li>
<li>\(\to_G\) - отношение &quot;произошло до&quot; на \(G\)</li>
<li>\(inv, res : H \to G\)
<ul>
<li>\(\forall e \in H : inv(e) \to_G res(e)\)</li>
<li>Все точки \(e\) лежат между \(inv\) и \(res\): \(\forall e \in H, g \in e, g \neq inv(e), g \neq res(e): inv(e) \to_G g \to_G res(e)\)</li>
</ul>
</li>
</ul>
<p>$$\forall e, f \in H : E \to_H f \stackrel{def}{=} res(e) \to_G inv(f)$$</p>
<p>Исполнение \(H, \to_H\) <strong>линеаризуемо</strong>, если можно найти исполнение \(L(H), \to_{L(H)}\), называемое <strong>линеаризацией</strong> \(H\), такое что:</p>
<ul>
<li>\(L(H) = H\) </li>
<li>Сохраняется старое отношение \(\to_H\): \(e \to_H f \implies e \to_{L(H)} f\)</li>
<li>Исполнение последовательно: \((e = f) \lor (e \to_{L(H)} f) \lor (f \to_{L(H)} e)\)</li>
<li>\(L(H)\) допустимо, т.е. выполняет последовательные спецификации всех объектов</li>
</ul>
<p><strong>Точки линеаризации</strong> это функция \(p : H \to G\) вместе с линеаризацией \((L(P), \to_{L(P)})\), где \(P = p(H)\)</p>
<p><em>Теорема:</em> Исполнение \(H\) линеаризуемо тогда и только тогда, когда можно выбрать точки линеаризации \(p\) согласовано с линеаризацией, т.е. \(e \to_{L(H)} f \iff p(e) \to_{L(P)} p(f)\)</p>
<h2 id="Есть-точки-линеаризации-implies-линеаризуемо"><a class="header" href="#Есть-точки-линеаризации-implies-линеаризуемо">Есть точки линеаризации \(\implies\) линеаризуемо</a></h2>
<p>Определим \(L(H)\) как \(e \to_{L(H)} f \iff p(e) \to_{L(P)} p(f)\), тогда старое отношение сохраняется, исполнение последовательно (порядок полный) и допустимо. Докажем, что \(\to_{L(H)}\) сохранняет \(\to_H\).</p>
<p><img src="img/proof2.png" alt="Proof2" /></p>
<h2 id="Линеаризуемо-implies-есть-точки-линеаризации"><a class="header" href="#Линеаризуемо-implies-есть-точки-линеаризации">Линеаризуемо \(\implies\) есть точки линеаризации</a></h2>
<p><img src="img/no_dot.png" alt="" /></p>
<p>Это неверно. Однако, можно доопределить точки и тогда искомое очевидно верно.
В частности, в модели глобального времени можно найти искомые точки.</p>
<p>Таким образом, для доказательство линеаризуемости достаточно предъявить точки линеаризации, но их может не быть и тогда надо доказывать по-другому (сложно).</p>
<p>Если объект линеаризуем, то можно опустить детали его реализации.</p>
<p>Пусть мы написали в псевдокоде:</p>
<pre><code class="language-python">def seq:
    op1
    op2
</code></pre>
<p>Тогда \(op1 \to op2\) и \(inv(seq) := inv(op1), res(seq) := res(op2)\) и каждая строчка атомарна, что позволяет нам анализировать через чередование.</p>
<p>Не любой линеаризуемый алгоритм можно реализовать таким образом.</p>
<h2 id="Блокировки"><a class="header" href="#Блокировки">Блокировки</a></h2>
<p>Mutex = mutual excluesion = lock = блокировка. Обладает свойством <strong>взаимного исключения</strong>, т.е. что выполнение критических секций не может быть параллельным, а следовательно оно будет линеаризуемо. Это требование <strong>корректности</strong> протокола взаимной блокировки.</p>
<h3 id="Первая-попытка"><a class="header" href="#Первая-попытка">Первая попытка</a></h3>
<pre><code class="language-python">shared boolean want
def lock:
    while want:
        pass
    want = True

def unlock:
    want = False
</code></pre>
<p>Не работает, т.к. два потока могут увидеть <code>want == false</code>, записать <code>want = true</code> и перейти в критическую секцию.</p>
<h3 id="Вторая-попытка"><a class="header" href="#Вторая-попытка">Вторая попытка</a></h3>
<pre><code class="language-python">threalocal int id # 0 or 1
shared boolean want[2]

def lock:
    want[id] = True
    while want[1 - id]:
        pass

def unlock:
    want[id] = False
</code></pre>
<p>Докажем взаимное исключение от противного через чередование, т.к. все строки атомарны.</p>
<p>Пусть два потока зашли одновременно в критическую секцию. Тогда поток <code>id</code> зашел последним в то время, как поток <code>1 - id</code> уже был в секции. Но в секцию можно зайти только после чтения <code>want[1 - id] == false</code>, это противоречит тому что <code>1 - id</code> в секции.</p>
<p>Однако, есть проблема - оба потока могут записать <code>want[id] = true</code> и вечно ждать друг друга.</p>
<p>Добавим новое условие: <strong>отсутствие взаимной блокировки (deadlock-freedom)</strong>: если несколько потоков пытаются войти в критическую секцию, то хотя бы один из них должен войти в критическую секцию за конечное время (если критические секции выполняются за конечное время).</p>
<h3 id="Третья-попытка"><a class="header" href="#Третья-попытка">Третья попытка</a></h3>
<pre><code class="language-python">threalocal int id # 0 or 1
shared int victim

def lock:
    victim = id
    while victim == id:
        pass

def unlock:
    pass
</code></pre>
<p>Доказать взаимное исключение тривиально (как в попытке 2). Докажем deadlock-freedom. Если два потока одновременно крутятся в цикле, то <code>victim == 0 &amp; victim == 1</code> - противоречие.</p>
<p>Есть другая проблема - если второй поток не хочет зайти в секцию, то <code>victim == 0</code> всегда и первый поток не зайдёт.</p>
<p>Добавим третье условие: <strong>отсутствие голодания (stavation-freedom)</strong>: если какой-то поток пытается войти в критическую секцию, то он войдёт в критическую секцию за конечное время (если критические секции выполняются за конечное время).</p>
<h3 id="Алгоритм-Петерсона"><a class="header" href="#Алгоритм-Петерсона">Алгоритм Петерсона</a></h3>
<pre><code class="language-python">threadlocal int id # 0 or 1
shared boolean want[2]
shared int victim

def lock:
    want[id] = true
    victim = id
    while want[1 - id] and victim == id:
        pass

def unlock:
    want[id] = false
</code></pre>
<p>Гарантирует все наши условия.</p>
<p>Докажем взаимное исключение. Пусть поток <code>id</code> зашел в CS последним, когда <code>1 - id</code> уже был в CS. Тогда либо <code>want[1 - id] == false</code> или <code>victim != id</code>.</p>
<ol>
<li><code>want[1 - id] == false</code>. Это противоречит тому что <code>want[1 - id] == true</code>, т.к. <code>1 - id</code> в CS.</li>
<li><code>victim != id</code>.
<ul>
<li>Если <code>1 - id</code> зашел по причине <code>victim != 1 - id</code>, то противоречие.</li>
<li>Остается случай <code>1 - id</code> зашел по причине <code>want[id] = false</code>, но тогда он зашел до исполнения первой строки потоком <code>id</code>, но тогда для потока <code>id</code> выполнено <code>victim == id</code>.</li>
</ul>
</li>
</ol>
<p>Взаимной блокировки нет в силу <code>victim</code>.</p>
<p>Голодания нет т.к. <code>want[1 - id] == false</code>.</p>
<p>Таким образом, для реализации лока достаточно иметь атомарные регистры чтения/записи.</p>
<h2 id="Алгоритм-Петерсона-для-n-потоков"><a class="header" href="#Алгоритм-Петерсона-для-n-потоков">Алгоритм Петерсона для N потоков</a></h2>
<pre><code class="language-python">threadlocal int id # 0 to N - 1
shared int level[N]
shared int victim[N]

def lock:
    for j in 1 .. N - 1:
        level[id] = j
        victim[j] = id
        while exist k: k != id and level[k] &gt;= j and victim[j] == id:
            pass

def unlock:
    level[id] = 0
</code></pre>
<p>Удовлетворяет тем же требованиям, но алгоритм не очень честный. Невезучий поток может ждать, пока другие потоки \(\mathcal O(N^2)\) раз войдут в критическую секцию. Хотелось бы ждать линейно.</p>
<h2 id="Алгоритм-Лампорта-булочника"><a class="header" href="#Алгоритм-Лампорта-булочника">Алгоритм Лампорта (булочника)</a></h2>
<pre><code class="language-python">threadlocal int id # 0 to N - 1
shared boolean want[N] init false
shared int label[N] init 0

def lock:
    want[id] = true
    label[id] = max(label) + 1
    while exists k: k != id and want[k] and (label[k], k) &lt; (label[id], id):
        pass

def unlock:
    want[id] = false
</code></pre>
<p>Идея: получаем номерок <code>label</code>, который больше всех предыдущих. Но может быть проблема: разные потоки получили один и тот же номер. Поэтому сравниваются не только номерки, но и номера потоков.</p>
<p>Ключевое свойство: если поток P выполнил первые две строки до Q, то он войдёт в секцию раньше. Это более сильное требование, называемое <strong>First come, first served</strong>:</p>
<ol>
<li>Метод <code>lock</code> состоит из двух последовательных секций:</li>
</ol>
<pre><code class="language-python">def lock:
    doorway
    waiting
</code></pre>
<ol start="2">
<li>Секция <code>doorway</code> является <code>wait free</code> (не ждём другие потоки)</li>
<li>Пусть время исполнения <code>doorway</code> это \(DW_i\), а операций <code>waiting</code> это \(WT_i\).</li>
<li>Если \(DW_i \to DW_j\), то \(res(WT_i) \to re(WT_j)\).</li>
</ol>
<p>Это немножко нечестно - метки должны быть бесконечными. Однако, можно устроить &quot;бесконечные&quot; метки на конечных регистрах.</p>
<p>Обычно говорят, что алгоритм <strong>честный</strong>, если он <strong>FCFS</strong>.</p>
<p>Блокировка позволяет избежать гонок.</p>
<h2 id="test-and-set-compare-and-set-spin-lock"><a class="header" href="#test-and-set-compare-and-set-spin-lock">Test-and-set (compare-and-set) spin lock</a></h2>
<pre><code class="language-python">def lock:
    while !locked.CAS(0, 1):
        pass

def unlock:
    locked = 0
</code></pre>
<p>На практике мы не хотим кушать CPU, пока ждём, поэтому немного spinимся, а потом спим через ОС. На реальном железе не масштабируется и в реальности не используется.</p>
<h2 id="Тонкая-блокировка"><a class="header" href="#Тонкая-блокировка">Тонкая блокировка</a></h2>
<p>Мы хотим использовать различные блокировки на разных переменных. Но это опасно - можно получить неверное исполнение. Например:</p>
<p><img src="img/stack_fail.png" alt="" /></p>
<p>Есть принцип <strong>2-Phase Locking</strong>:</p>
<ol>
<li>Берём блокировки на все необходимые объекты</li>
<li>Выполняем операцию</li>
<li>Отпускаем все блокировки</li>
</ol>
<p>Брать и отпускать блокировки можно в любом порядке.</p>
<p>2PL всегда линеаризуемо (точка линеаризации между фазами).</p>
<p>Все следующие операции 2PL:</p>
<pre><code class="language-python">def proc1:
    mutex1.lock
    mutex2.lock
    obj1.work
    obj2.work
    mutex2.unlock
    mutex1.unlock
</code></pre>
<pre><code class="language-python">def proc2:
    mutex1.lock
    obj1.work
    mutex2.lock
    obj2.work
    mutex2.unlock
    mutex1.unlock
</code></pre>
<pre><code class="language-python">def proc3:
    mutex1.lock
    mutex2.lock
    obj1.work
    obj2.work
    mutex1.unlock
    mutex2.unlock
</code></pre>
<p>С помощью блокировок можно сделать любой объект линеаризуемым. Однако есть проблема: может произойти deadlock - если два процесса ждут друг друга (с двумя блокировками). Это решается с помощью выстраивания блокировок в иерархию, где мы захватываем сначала более приоритетные блокировки.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-31-Практические-построения-на-списках"><a class="header" href="#Лекция-31-Практические-построения-на-списках">Лекция 3.1 Практические построения на списках</a></h1>
<h2 id="Множество-на-односвязном-списке"><a class="header" href="#Множество-на-односвязном-списке">Множество на односвязном списке</a></h2>
<p>Это казалось бы игрушечная структура данных, но она используется в очень полезном skip listе.</p>
<p>Пусть в списке у нас есть граничные элементы \(-\infty, +\infty\).</p>
<ul>
<li>Элементы упорядочены по возрастанию</li>
<li>Мы ищем окно (<code>cur</code>, <code>next</code>), такое что <code>cur.key</code> \(&lt;\) <code>k</code> \(\leq\) <code>next.key</code> и <code>cur.N = next</code></li>
<li>Если мы ищем элемент, то он будет в <code>next</code> (или его не будет)</li>
<li>Новый элемент будем добавлять между <code>cur</code> и <code>next</code>.</li>
</ul>
<p>Псевдокод:</p>
<pre><code class="language-kotlin">class Node(var N: Node, val key: Int)

val head = Node(−∞, Node(∞, null))

fun findWindow(key): (Node, Node) {
    cur := head
    next := cur.N
    while (next.key &lt; key):
        cur = next
        next = cur.N
    return (cur, next)
}

fun contains(key): Boolean {
    (cur, next) := findWindow(key)
    return next.key == key
}

fun add(key) {
    (cur, next) := findWindow(key)
    if (next.key != key)
        cur.N = Node(key, next)
}

fun remove(key) {
    (cur, next) := findWindow(key)
    if (next.key == key)
        cur.N = next.N
}
</code></pre>
<p>Проблема, удаление последовательных вершин в различных потоках может не сработать.</p>
<p><code>a -&gt; b -&gt; c -&gt; d</code> станет <code>a -&gt; c -&gt; d</code> и <code>b -&gt; d</code>, в итоге <code>c</code> не удалено.</p>
<p>Можно навесить грубую синхронизацию, но это неэффективно.</p>
<h3 id="Тонкая-синхронизация"><a class="header" href="#Тонкая-синхронизация">Тонкая синхронизация</a></h3>
<p>Можно навесить лок на каждую вершину. Тогда поток будет держать блокировку на <code>cur</code> и <code>next</code>. В коде это будет выглядеть так:</p>
<pre><code class="language-kotlin">fun findWindow(key): (Node, Node) {
    cur := head; cur.lock()
    next := cur.N; next.lock()
    while (next.key &lt; key):
        cur.unlock(); cur = next
        next = cur.N; next.lock()
    return (cur, next)
}

fun contains(key): Boolean {
    (cur, next) := findWindow(key)
    cur.unlock(); next.unlock()
    return next.key == key
}
</code></pre>
<h3 id="Оптимистичная-синхронизация"><a class="header" href="#Оптимистичная-синхронизация">Оптимистичная синхронизация</a></h3>
<ol>
<li>Найти окно без синхронизации.</li>
<li>Взять блокировки на <code>cur</code> и <code>next</code>.</li>
<li>Проверить, что <code>cur.N == next</code>.</li>
<li>Проверить, что <code>cur</code> не удален.</li>
<li>Выполнить операцию.</li>
<li>При ошибке попробовать заново.</li>
</ol>
<p>При проверке, что <code>cur</code> не удален, мы держа блокировку на него, ищем его еще раз в линию.</p>
<pre><code class="language-kotlin">class Node(@Volatile var N: Node, val key: Int)

fun contains(key): Boolean {
    while (true) {
        (cur, next) := findWindow(key)
        cur.lock(); next.lock()
        if (!validate(cur, next))
            cur.unlock(); next.unlock(); continue
        return next.key == key
    }
}

fun validate(cur, next): Boolean {
    var node = head
    while(node.key &lt; cur.key):
    node = node.N
    return (cur, next) == (node, node.N)
}
</code></pre>
<h3 id="Ленивая-синхронизация"><a class="header" href="#Ленивая-синхронизация">Ленивая синхронизация</a></h3>
<p>Будем лениво удалять. В <code>Node</code> добавляем <code>removed: Boolean</code>. Удаление будет происходить в две фазы:</p>
<ol>
<li><code>node.removed = true</code> - логическое удаление</li>
<li>Физическое удаление</li>
</ol>
<p>Тогда валидация тривиальна:</p>
<pre><code class="language-kotlin">fun validate(cur, next) = !cur.removed &amp;&amp; !next.removed &amp;&amp; cur.N == next
</code></pre>
<h3 id="Неблокирующая-синхронизация"><a class="header" href="#Неблокирующая-синхронизация">Неблокирующая синхронизация</a></h3>
<p>Т.к. <code>N</code> <code>volatile</code>, то мы увидели состояние памяти на момент записи в <code>N</code>. Поэтому мы можем не брать блокировку при поиске. Тогда:</p>
<pre><code class="language-kotlin">fun contains(key): Boolean {
    (cur, next) := findWindow(key)
    return next.key == key
}
</code></pre>
<p>Наивная запись на <code>CAS</code> опять не работает. <code>a -&gt; b -&gt; c -&gt; d</code> станет <code>a -&gt; c -&gt; d</code> и <code>b -&gt; d</code>, в итоге <code>c</code> не удалено. Проблема в том, что мы не знали, что <code>b</code> уже удалено. Казалось бы, можно написать двусвязный список, но нет, это очень сложно. Вместо этого объединим <code>N</code> и <code>removed</code> в одну переменную, пару <code>(N, removed)</code> и таким образом запретим делать изменения на <code>N</code>, если нода удалена. В java это <code>AtomicMarkableReference</code>, реализовано через обертку.</p>
<pre><code class="language-kotlin">fun findWindow(key): (Node, Node) {
    retry: while(true):
        var cur = head, next = cur.N
        boolean[] removed = new boolean[1]
        while (next.key &lt; key):
            val node = next.N.get(removed)
            if (removed[0]):
                // удалим физически
                if (!cur.N.CAS(next, node, false, false)):
                    continue retry
                next = node
            else:
                cur = next
                next = cur.N
        // тут еще проверка, что next не удален
        return (cur, next)
}

fun contains(key): Boolean {
    (cur, next) = findWindow(key)
    return next.key == key
}

fun add(key) {
    while(true):
        (cur, next) = findWindow(key)
        if (next.key == key):
            return
        val node = Node(key, next)
        if (cur.N.CAS(next, node, false, false)):
            return
}

fun remove(key) {
    while(true):
        (cur, next) = findWindow(key)
        if (next.key != key)
            return // false
        val node = next.N.getReference();
        if (next.N.CAS(node, node, false, true)):
            // помогаем findWindow удалить физически
            cur.N.CAS(next, node, false, false)
            return // true
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-32-relaxed-algorithms"><a class="header" href="#Лекция-32-relaxed-algorithms">Лекция 3.2. Relaxed Algorithms.</a></h1>
<h2 id="bfs"><a class="header" href="#bfs">BFS</a></h2>
<p>Вспомним обычный BFS:</p>
<pre><code class="language-kotlin">val Q = Queue&lt;Node&gt;()
start.distance = 0
Q.add(start)
while Q.isNotEmpty() {
    u := Q.remove()
    d := u.distance
    for (v : u.edges) {
        if v.distance != INF: continue
        v.distance = d + 1
        Q.add(v)
    }
}
</code></pre>
<p>Просто заменить <code>Queue</code> на <code>ConcurrentQueue</code> не поможет, т.к. первый поток удалит первую вершину из очереди, все остальные потоки выйдут из цикла и алгоритм станет однопоточным.</p>
<p>Можем считать число вершин в обработке вместо <code>Q.isNotEmpty()</code>. Тогда есть другая проблема: мы не гарантируем порядок обработки вершин, это никакой не BFS. Но нас это не очень и волнует, ибо мы будем обновлять расстояние только если оно меньше того, которое уже посчитано:</p>
<pre><code class="language-kotlin">val Q = Queue&lt;Node&gt;()
start.distance = 0
Q.add(start)
activeNodes = 1
while activeNodes &gt; 0 {
    u := Q.remove()
    d := u.distance
    for (v : u.edges) {
        if v.updateDistIfLower(d + 1) {
            v.distance = d + 1
            Q.add(v)
            activeNodes++
        }
    }
    activeNodes--
}
</code></pre>
<p>С одной стороны, мы одну вершину обрабатываем одну вершину несколько раз, но с другой — мы параллельны. На реальных графах это профит.</p>
<h2 id="Алгоритм-Дейкстры"><a class="header" href="#Алгоритм-Дейкстры">Алгоритм Дейкстры</a></h2>
<p>Дейкстра это примерно то же самое, что у нас, только у нас приоритетная очередь. Быстрая приоритетная очередь это миф, лучший случай это куча с локами. Но мы можем написать <strong>почти</strong> приоритетную очередь. Тогда алгоритм всё ещё будет верным, но у нас опять будут инверсии.</p>
<h3 id="multi-queue"><a class="header" href="#multi-queue">Multi-Queue</a></h3>
<p>Возьмём T независимых очередей с локами. Операции пусть будут работать над случайно выбранными очередями.</p>
<ul>
<li>Добавление: добавляем в случайную очередь</li>
<li>Удаление: берем <strong>две</strong> случайные очереди и удаляем из лучшей.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-41-Алгоритмы-без-блокировок-Построения-на-регистрах"><a class="header" href="#Лекция-41-Алгоритмы-без-блокировок-Построения-на-регистрах">Лекция 4.1. Алгоритмы без блокировок: Построения на регистрах</a></h1>
<p>Мы не можем требовать, чтобы алгоритм не использовал блокировку, ибо это нечто непонятное. Вместо этого мы будем использовать одно из безусловных <strong>условий прогресса</strong></p>
<h3 id="Отсутствие-помех-obstruction-freedom"><a class="header" href="#Отсутствие-помех-obstruction-freedom">Отсутствие помех (obstruction-freedom)</a></h3>
<p>Если несколько потоков пытаются выполнить операцию, то любой из них должен выполнить её за конечное время, если все другие потоки остановить в любом месте.</p>
<p>Это условие слабое.</p>
<h3 id="Отсутствие-блокировок-lock-freedom"><a class="header" href="#Отсутствие-блокировок-lock-freedom">Отсутствие блокировок (lock-freedom)</a></h3>
<p>Если несколько потоков пытаются выполнить операцию, то хотя бы один из них должен выполнить её за конечное время (независимо от действия/бездействия других потоков).</p>
<p>На практике используется именно lock-freedom.</p>
<p>Для hard realtime систем это условие недостаточно, так как нет условия, что все потоки вовремя все сделают.</p>
<h3 id="Отсутствие-ожидания-wait-freedom"><a class="header" href="#Отсутствие-ожидания-wait-freedom">Отсутствие ожидания (wait-freedom)</a></h3>
<p>Если какой-то поток пытается выполнить операцию, то он выполнит ее за конечное время независимо от действия или бездействия других потоков.</p>
<p>С блокировкой объект не может быть obstruction-free.</p>
<h2 id="Регистр"><a class="header" href="#Регистр">Регистр</a></h2>
<p>Последовательная спецификация:</p>
<pre><code class="language-python">class Register:
    int r
    
    def write(x):
        r = x
    
    def read():
        return r
</code></pre>
<p>Физические регистры не атомарны</p>
<ul>
<li>Без ожидания</li>
<li>Один читатель</li>
<li>Один писатель</li>
<li>Чтение и запись одновременно приводит к непредсказуемым результатам</li>
<li><strong>Безопасны</strong>: после завершения записи будет прочитано последнее записанное значение</li>
</ul>
<p>Построим более полезный регистр. Это сугубо теоретическое упражнение, но идеи из него применимы на практике.</p>
<p>Небезопасный регистр бесполезен.</p>
<h3 id="Регулярные-регистры"><a class="header" href="#Регулярные-регистры">Регулярные регистры</a></h3>
<p>При чтении выдает либо последнее записанное значение, либо одно из тех значений, что сейчас пишутся.</p>
<p><img src="img/regular.png" alt="" /></p>
<h3 id="Атомарные-регистры"><a class="header" href="#Атомарные-регистры">Атомарные регистры</a></h3>
<p>Исполнение линеаризуемо.</p>
<p><img src="img/atomic.png" alt="" /></p>
<h3 id="Регулярный-srsw-булев-регистр"><a class="header" href="#Регулярный-srsw-булев-регистр">Регулярный SRSW булев регистр</a></h3>
<p>Дано: безопасный SRSW булев регистр</p>
<pre><code class="language-python">safe shared boolean r
threadlocal boolean last

def write(x):
    if x != last:
        last = x
        r = x

def read():
    return r
</code></pre>
<p>Так как у нас только один писатель и регистр булев, то мы просто не перезаписываем последнее записанное значение.</p>
<h3 id="Регулярный-srsw-регистр-m-значений"><a class="header" href="#Регулярный-srsw-регистр-m-значений">Регулярный SRSW регистр, M значений</a></h3>
<p>Дано: Регулярный SRSW булев регистр</p>
<p>Запоминаем M значений в унарном коде с помощью M регистров. Тогда индекс первого нуля — значение. Пишем справа налево, а читаем слева направо.</p>
<pre><code class="language-python">regular shared boolean[M] r

def write(x): # справа налево
    r[x] = 0
    for i = x - 1 downto 0: r[i] = 1

def read(): # слева направо
    for i = 0 to M - 1:
        if r[i] == 0:
            return i
</code></pre>
<h3 id="Атомарный-srsw-регистр-с-версиями"><a class="header" href="#Атомарный-srsw-регистр-с-версиями">Атомарный SRSW регистр с версиями</a></h3>
<p>Дано: Регулярный SRSW регистр на M значений</p>
<pre><code class="language-python">regular shared (int x, int v) r

threadlocal (int x, int v) lastRead
threadlocal int lastWriteV

def write(x):
    lastWriteV++
    r = (x, lastWriteV)

def read():
    cur = r
    if cur.v &gt; lastRead.v
        lastRead = cur
    return lastRead.x
</code></pre>
<p>В теории версии растут неограниченно, поэтому проблема.</p>
<p><em>Теорема: (вне курса)</em> Не существует алгоритма построения атомарного регистра без ожидания, которые использует конечное число регулярных регистров конечного размера так, чтобы их писал только писатель, а читал только читатель.</p>
<p>Вывод: нужна обратная связь от читателя к писателю. Мы не будем это рассматривать.</p>
<h3 id="Атомарный-mrsw-регистр"><a class="header" href="#Атомарный-mrsw-регистр">Атомарный MRSW регистр</a></h3>
<p>Дано: атомарный SRSW регистр M значений</p>
<p>Идея: заведет по регистру для каждого читателя и будем писать в них.</p>
<p><img src="img/mrsw.png" alt="" /></p>
<p>Очень жаль, идея не работает:</p>
<p><img src="img/mrsw_fail.png" alt="" /></p>
<p>Заведём ещё \(n(n-1)\) регистров для общения между читателями.</p>
<ul>
<li>Каждый читатель выбирает более позднее значение из
записанного писателем и из прочитанных значений других
читателей.</li>
<li>После этого читатель записывает свое прочитанное значение и
версию для всех остальных читателей.</li>
</ul>
<p><img src="img/mrsw_real.png" alt="" /></p>
<h3 id="Атомарный-mrmw-регистр-с-версиями"><a class="header" href="#Атомарный-mrmw-регистр-с-версиями">Атомарный MRMW регистр с версиями</a></h3>
<p><img src="img/mrmw.png" alt="" /></p>
<p>Писатели будут между собой по алгоритму булочника выбирать билетик. Билетиком штампуют записанное значение, читатели выбирают самое позднее.</p>
<h3 id="Атомарный-снимок-состояния-n-регистров"><a class="header" href="#Атомарный-снимок-состояния-n-регистров">Атомарный снимок состояния N регистров</a></h3>
<p>Последовательная спецификация:</p>
<pre><code class="language-python">class Snapshot:
    shared int r[N]

    def update(i, x):
        r[i] = x

    def scan():
        return copy()

    private def copy():
        res = new int[N]
        for i = 0..N-1: res[i] = r[i]
        return res
</code></pre>
<pre><code class="language-python">shared (int x, int v) r[N]

# wait-free
def update(i, x):
    sr[i] = (x, r[i].v + 1)

# lock-free
def scan():
    old = copy()
    loop:
        cur = copy()
        if forall i: cur[i].v == old[i].v:
            return cur.x
    old = cur
</code></pre>
<p>При большом числе <code>update</code> <code>scan</code> виснет. Поэтому пусть каждый регистр хранит копию снимка и при обновлении будем делать <code>scan</code>, чтобы помочь другим операциям.</p>
<pre><code class="language-python">shared (int x, int v, int[N] s) r[N]

def update(i, x):
    s = scan()
    r[i] = (x, r[i].v + 1, s)

# wait-free, O(N^2)
def scan():
    old = copy()
    boolean updated[N]
        loop:
            cur = copy()
            for i = 0..N-1:
                if cur[i].v != old[i].v:
                    if updated[i]: return cur[i].s
                    else:
                        update[i] = true
                        old = cur
                        continue loop
        return cur.x
</code></pre>
<p><em>Лемма:</em> Если значение изменилось второй раз, то хранящаяся там копия снимка s была получена вложенной операцией scan.</p>
<p><img src="img/shot.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-42-Алгоритмы-без-блокировок-Консенсус"><a class="header" href="#Лекция-42-Алгоритмы-без-блокировок-Консенсус">Лекция 4.2. Алгоритмы без блокировок: Консенсус</a></h1>
<h2 id="Консенсус"><a class="header" href="#Консенсус">Консенсус</a></h2>
<p>На практике не используется, это сугубо теоретическая конструкция. Консенсус одноразовый.</p>
<pre><code class="language-python">class Consensus:
    def decde(val):
        return val
</code></pre>
<ul>
<li><strong>Согласованность</strong>: всем потокам возвращается одно и то же значение из метода <code>decide</code>.</li>
<li><strong>Обоснованность</strong>: возвращенное значение это входное значение какого-то из потоков.</li>
</ul>
<p>С помощью блокировки консенсус тривиален:</p>
<pre><code class="language-python">shared int decision // init NA
Mutex mutex

def decide(val):
    mutex.lock()
    if decision == NA:
        decision = val
    mutex.unlock()
    return decision
</code></pre>
<p>А что если мы хотим без ожидания? Для произвольного числа потоков это невозможно.</p>
<p>Если с помощью класса (атомарных) объектов C и атомарных регистров можно реализовать консенсусный протокол без ожидания с помощью детерминированного алгоритма для N потоков (и не больше), то говорят, что у класса C <strong>консенсусное число</strong> равно N.</p>
<p><em>Теорема:</em> атомарные регистры имеют консенсусное число 1.</p>
<p><em>Доказательство:</em> пусть два потока решают задачу бинарного консенсуса.</p>
<ul>
<li>Рассмотрим граф состояний. Он конечен и без циклов, т.к. алгоритм без ожидания.</li>
<li>Листья графа - 0 или 1.</li>
<li>Состояние системы x-валентно, где x=0 или 1, если консенсус во всех листьях ниже будет x.</li>
<li>Состояние бивалентно если оно не 0-валентно и не 1-валентно.</li>
<li>Критическое состояние — бивалентное состояние, дети которого не бивалентны</li>
<li>Состояние (decide(1), decide(1)) 1-валентно, т.к. оно может выдать только 1.</li>
<li>Состояние (decide(0), decide(1)) бивалентно, т.к. если переходить всегда по левому аргументу, то получится 0. Если по второму, то 1.</li>
<li>Критическое состояние есть в силу конечности дерева и существования бивалентного</li>
<li>Если из критического состояния мы переходим коммутирующими операциями, то мы придём в одну и ту же вершину.</li>
<li>Тогда пусть мы идём не коммутирующими операциями, то есть чтение/запись + запись.</li>
<li>Пусть одна операция над регистром \(w\), а другая над регистром \(g\). Тогда пусть мы выполним дальше только действия над регистром \(w\). Система будет в том же состоянии, что и после той операции над \(w\). Следовательно, мы придём в состояние валентности после той операции, что невозможно.</li>
</ul>
<p>Таким образом, для консенсуса нужны более сильные примитивы.</p>
<h3 id="read-modify-write-регистры"><a class="header" href="#read-modify-write-регистры">Read-Modify-Write регистры</a></h3>
<pre><code class="language-python">class RMWRegister:
    private shared int reg
    
    def read():
        return reg
    
    def getAndF(f):
        atomic:
            old = reg
            reg = f(reg)
            return old
</code></pre>
<p>Здесь <code>f</code> это простая операция, наподобие <code>set</code> или <code>add</code>.</p>
<p>Консенсусное число нетривиального RMW регистра &gt;= 2. Нетривиально в данном случае — существование хотя бы одной подвижной точки функции, т.е. \(f(v_0) = v_1 \neq v_0\).</p>
<h3 id="common2-rmw-регистры"><a class="header" href="#common2-rmw-регистры">Common2 RMW регистры</a></h3>
<ul>
<li>\(f_1\) и \(f_2\) коммутируют, если \(f_1(f_2(x)) = f_2(f_1(x))\).</li>
<li>\(f_1\) перезаписывает \(f_2\), если \(f_1(f_2(x)) = f_1(x)\)</li>
<li>Класс C RMW регистров принадлежит Common2, если любая пара функций либо коммутирует, либо одна из функций перезаписывает другую.</li>
</ul>
<p><em>Теорема:</em> нетривиальный класс Common2 RMW регистров имеет консенсусное число 2.</p>
<p>Пример операций: <code>compareAndSet: Boolean</code>, <code>compareAndExchange: old</code>. Они позволяют привести к консенсусу произвольное число потоков, т.е. их консенсусное число — бесконечность. Такие объекты называются универсальными.</p>
<pre><code class="language-python">def decide(val):
    if CAS(NA, val):
        return val
    else:
        return read()
</code></pre>
<h2 id="Универсальность-консенсуса"><a class="header" href="#Универсальность-консенсуса">Универсальность консенсуса</a></h2>
<p><em>Теорема:</em> любой последовательный объект можно реализовать без ожидания для N потоков, используя консенсусный протокол для N потоков. Такое построение называется <strong>универсальная конструкция</strong>.</p>
<h3 id="Универсальная-конструкция-без-блокировки-через-cas"><a class="header" href="#Универсальная-конструкция-без-блокировки-через-cas">Универсальная конструкция без блокировки через CAS</a></h3>
<pre><code class="language-python">shared CASRegister reg

def concurrentOperationX(args):
    loop:
        old = reg.read()
        upd = old.deepCopy() # все поля структуры
        res = upd.serialOperationX(args) # последовательная спецификация
    until reg.CAS(old, upd)
    return res
</code></pre>
<p>Но у нас есть две проблемы — нам нужно wait-free и на консенсусе.</p>
<p>Представим объект в виде списка состояний, где последний элемент — текущее состояние.</p>
<pre><code class="language-python">class Node:
    val # readonly
    Consensus next # init fresh cons

shared Node root # readonly
threadlocal Node last # init root

def concurrentOperationX(args):
    loop:
        old = last.val
        upd = old.deepCopy() # все поля структуры
        res = upd.serialOperationX(args) # последовательная спецификация
        node = new Node(upd)
        last = last.next.decide(node)
    until last == node # until we're accepted into the list
    return res
</code></pre>
<p>Мы очевидно не блокаемся, но не без ожиданий.</p>
<p>Идеи:</p>
<ol>
<li>Храним в узле операцию, которую надо выполнить, а не результат ее выполнения. Тогда каждый поток будет хранить и обновлять свою локальную копию объекта.</li>
<li>Занумеруем операции</li>
<li>Какой-то поток может отстать, проигрывая консенсус и из-за этого ожидая. Пусть каждый потом шарит другим потокам последнее известное ему значение конца списка в <code>know[id]</code>.</li>
<li>Нужна помощь от быстрых: будем анонсировать свою операцию, а выполнять чужую. Тогда за N шагов каждому потоку помогут.</li>
</ol>
<pre><code class="language-python">shared Node[] know // init root

def concurrentOperationX(args):
    announce[id] = new Node(args)
    know[id] = maxSeqFrom(know)
    # loop until we’re is in list
    while announce[id].seq == 0:
        Node help = announce[know[id].seq % N]
        Node prev = help if help.seq == 0 else announce[id]
        know[id] = prev.next.decide(node)
        know[id].seq = prev.seq + 1
    know[id] = announce[id]
    return updateMyLastTo(announce[id])

def updateMyLastTo(node):
    while last != node:
        res = my.serialOperationX(last.args)
        last = last.next
    return res
</code></pre>
<p>В реальности строят более эффективный алгоритм на <code>CAS</code>ах, а скорее просто используют уникальный алгоритм для каждой структуры.</p>
<p>Очень хорошо эта идея работает на персистентных структурах (привет clojure). На самом деле Treiber stack персистентный. Для алгоритмов на <code>CAS</code> циклах очень просто доказать линеаризуемость — точка успешного <code>CAS</code> это точка линеаризации.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-5-jmm"><a class="header" href="#Лекция-5-jmm">Лекция 5. JMM</a></h1>
<p>JMM делалась давно и не везде было 64 бита. Поэтому <code>long</code> и <code>double</code> не атомарный по железу и тогда надо устраивать синхронизацию. Решили этого не делать и не гарантировать атомарность, хотя в реальности она гарантирована. По JMM доступ атомарен для всех базовых типов, кроме <code>long</code> и <code>double</code>. К <code>volatile long</code> и <code>volatile double</code> атомарен.</p>
<p>На очень старом железе возможно, что напечатает <code>0xFFFFFFFF00000000</code>:</p>
<pre><code class="language-java">// before
long l = 0;

// thread 0
l = -1; // 0xFF..F

// thread 1
print(l);
</code></pre>
<h3 id="word-tearing"><a class="header" href="#word-tearing">Word tearing</a></h3>
<pre><code class="language-java">// before
T[] tarr = new T[..];
tarr[0] = tarr[1] = val0;

// thread 0
tarr[0] = val1;

// thread 1
tarr[1] = val1;

// thread 2
join t0, t1;
assert(tarr[0] == tarr[1]);
</code></pre>
<p>В JVM обновление двух независимых переменных независимо. Это поддерживается железом.</p>
<p>А что делать с <code>boolean</code>? Будем делать <code>boolean</code> 1 байт. Если хотим эффективные биты, то можно использовать <code>BitSet</code>. Но тогда нет гарантий про word tearing и в аналогичном коде <code>assert</code> может упасть (см. выше)</p>
<p>Модель памяти это компромисс между удобством программирования, сложностью реализации языка и поддержки со стороны железа.</p>
<h3 id="Последовательная-согласованность-1"><a class="header" href="#Последовательная-согласованность-1">Последовательная согласованность</a></h3>
<p>В целом мы хотим иметь последовательную согласованность, чтобы можно было анализировать чередованием. Но это усложняет локальные оптимизации.</p>
<p>По JMM, если в исполнении нет гонок (нет параллельных конфликтующих операций), то оно последовательно согласованно. Но что такое &quot;параллельно&quot; с точки зрения JMM?</p>
<h3 id="program-order"><a class="header" href="#program-order">Program order</a></h3>
<p>Программный порядок связывает действия внутри одного потока.</p>
<h3 id="synchronization-actions"><a class="header" href="#synchronization-actions">Synchronization actions</a></h3>
<p>Это:</p>
<ul>
<li><code>volatile</code> чтение/запись</li>
<li>Взятие/отпускание блокировки</li>
<li>Первое и последнее действие в потоке</li>
<li>Запуск потока</li>
<li>Действия, обнаруживающее останов потока</li>
</ul>
<p>Все synchronization actions образую <strong>synchronization order</strong>. Это линейный порядок и он консистентен с program order. Все чтения в synchronization order видят последние записи в synchronization order.</p>
<h3 id="synchronizes-with-order"><a class="header" href="#synchronizes-with-order">Synchronizes-with order</a></h3>
<p>SO это очень мощно, мы будем использовать SW - подпорядок SO, ограниченный парными действиями синхронизации, например <code>volatile</code> read/write над одной и той же переменной.</p>
<h3 id="happens-before-order"><a class="header" href="#happens-before-order">Happens-before order</a></h3>
<p>\(HB = (SW \cup PO)^+\)</p>
<p>Чтения видят либо последнюю запись по HB, либо что-то еще под гонкой.</p>
<h3 id="final-семантика"><a class="header" href="#final-семантика">Final семантика</a></h3>
<p>В конце конструктора происходит freeze action, которое &quot;замораживает&quot; поля.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-6-faa-based-queue--flat-combining"><a class="header" href="#Лекция-6-faa-based-queue--flat-combining">Лекция 6. FAA-Based Queue &amp; Flat Combining</a></h1>
<h3 id="faa"><a class="header" href="#faa">FAA</a></h3>
<p>FAA это <code>Fetch-And-Add(addr, delta)</code>, атомарно увеличивает значение на <code>delta</code> и возвращает старое значение. Это лучше масштабируется, чем <code>CAS</code> цикл, так как операция всегда успешна.</p>
<h3 id="obstruction-free-queue"><a class="header" href="#obstruction-free-queue">Obstruction-free queue</a></h3>
<p>Пусть у нас есть бесконечный массив с двумя указателями <code>enqIdx</code>, <code>deqIndx</code>. Что делать, если <code>dequeue</code> не увидел никакую запись? Тогда пометим ячейку как сломанную и обе операции начнутся заново.</p>
<pre><code class="language-kotlin">fun enqueue(x: T) = while (true) {
    val enqIdx = FAA(&amp;enqIdx, 1)
    if (CAS(&amp;data[enqIdx], null, x))
    return
}

fun dequeue() = while (true) {
    if (isEmpty()) return null
    val deqIdx = FAA(&amp;deqIdx, 1)
    val res = SWAP(&amp;data[deqIdx], BROKEN)
    if (res == null) continue
    return res
}

fun isEmpty(): Boolean = deqIdx &gt;= enqIdx
</code></pre>
<p>Это не lock-free, но на практике он почти lock-free. Кроме того, lock-free алгоритмы на практике почти всегда являются wait-free в силу честности планировщиков ОС.</p>
<p>В реальности у нас не бесконечный массив. Поэтому будем хранить Michal-Scott очередь сегментов.</p>
<pre><code class="language-kotlin">fun enqueue(x: T) = while (true) {
    val tail = this.tail
    val enqIdx = FAA(&amp;tail.enqIdx, 1)
    if (enqIdx &gt;= NODE_SIZE) {
        // try to insert new node with “x”
    } else {
        if (CAS(&amp;tail.data[enqIdx], null, x))
            return
    }
}

fun dequeue(): T = while (true) {
    val head = this.head
    val deqIdx = FAA(&amp;head.deqIdx, 1)
    if (deqIdx &gt;= NODE_SIZE) {
        val headNext = head.next ?: return null
        CAS(&amp;this.head, head, headNext)
        continue
    }
    val res = SWAP(&amp;head.data[deqIdx], BROKEN)
    if (res == null) continue
    return res
}
</code></pre>
<p>Тогда алгоритм lock-free.</p>
<h3 id="flat-combining"><a class="header" href="#flat-combining">Flat combining</a></h3>
<p>Идея: будем выполнять операции последовательно, структура данных защищена блокировкой. Поток, который держит блокировку — комбайнер, он выполняет как свою, так и чужие операции. Таким образом, мы не проигрываем по кешу и не так часто берем блокировку.</p>
<p>Это делается через массив, в который (случайно) кладутся дескрипторы операций. Держащий блокировку поток обходит весь массив и выполняет все операции, которые видит. Массив очевидно атомарный.</p>
<p>Очередь на flat combining куда быстрее, чем michael-scott. Однако FAA еще быстрее. В целом flat combining полезно, когда грубая/тонкая блокировка слишком медленно, а flat combining хватает. Бывает, что flat combining быстрее чем lock-free (см. очередь Michael-Scott).</p>
<p>Лок для flat combining очень простой: просто атомарный бул:</p>
<pre><code class="language-kotlin">var locked = false

fun tryLock() = CAS(&amp;lock, false, true)

fun unlock() { locked = false }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-71-Мониторы-и-ожидание"><a class="header" href="#Лекция-71-Мониторы-и-ожидание">Лекция 7.1. Мониторы и ожидание</a></h1>
<h2 id="Ожидание"><a class="header" href="#Ожидание">Ожидание</a></h2>
<p>Пусть операция над объектом это функция \(f(S, P) = (S', R)\). Раньше операции были всюду определены на паре \((S, P)\), то есть если операцию нельзя выполнить, то это исключение. Однако в общем случае операции могут быть частично определены, т.е. операция не может завершиться и ждет.</p>
<p>Например, очередь ограниченного размера с ожиданием:</p>
<ul>
<li><code>put(item)</code> - кладет элемент в очередь, <em>если есть место</em> (иначе ждет)</li>
<li><code>take(): item</code> - забирает элемент из очереди, <em>если очередь не пустая</em> (иначе ждет)</li>
</ul>
<p>Это часто происходит в паттерне producer-cosumer (привет, ГК).</p>
<p>Пусть в исполнении может не быть \(res(A)\). Тогда будем называть исполнение линеаризуемым, если для незавершенных операций можно:</p>
<ul>
<li>или добавить ответы,</li>
<li>или выкинуть их из исполнения</li>
</ul>
<p>Так, чтобы получилось допустимое последовательное исполнение.</p>
<h2 id="Мониторы"><a class="header" href="#Мониторы">Мониторы</a></h2>
<p>Это mutex + условные переменные.</p>
<p>В jvm у каждого объекта есть монитор с одной условной переменной, <code>wait</code>, <code>notify</code>, <code>notifyAll</code> работают с ней.</p>
<h3 id="Циклическая-очередь-на-массиве"><a class="header" href="#Циклическая-очередь-на-массиве">Циклическая очередь на массиве</a></h3>
<pre><code class="language-java">public class BlockingQueue&lt;T&gt; {
    private final T[] items; // элементы
    private final int n; // == items.length
    private int head; // голова
    private int tail; // хвост
    
    public synchronized int size() {
        return (tail - head + n) % n;
    }
    
    // не ждущий
    public synchronized T poll() {
        if (head == tail) return null;
        T result = items[head];
        items[head] = null;
        head = (head + 1) % n;
        return result;
    }
    
    // ждущий
    public synchronized T take() throws InterruptedException /* позже поговорим */ {
        while (head == tail) wait(); // ждем
        // wait может сам по себе проснуться, поэтому его надо делать в цикле
        T result = items[head];
        items[head] = null;
        head = (head + 1) % n;
        return result;
    }
}
</code></pre>
<p>Метод <code>wait</code> - часть монитора, освобождает блокировку и ждёт сигнала о пробуждении. Сингал посылается через <code>notify</code> и <code>notifyAll</code>. Оба могут быть использованы только в критической секции.</p>
<pre><code class="language-java">// не ждущий
public synchronized boolean offer(T item) {
    int next = (tail + 1) % n;
    if (next == head) return false;
    items[tail] = item;
    if (head == tail) notifyAll();
    tail = next;
    return true;
}

public synchronized void put(T item) throws Inter...Ex... {
    while (true) { // пока не подходящее состояние
        int next = (tail + 1) % n;
        if (next == head) { wait(); continue; }
        items[tail] = item;
        if (head == tail) notifyAll();
        tail = next;
        return;
    }
}
</code></pre>
<p>Нам не важно, где в коде вызван <code>notifyAll</code>.</p>
<p><code>notify</code> более точечный, потому что можно пробуждать только один поток. В нашем примере это не сработает, т.к. <code>put</code> может пробудить другой <code>put</code> поток, а нам нужно будить <code>take</code> потоки. Однако в <code>ReentrantLock</code> можно заводить условные переменные через <code>lock.newCondition()</code>. На других языках условные переменные используются только так.</p>
<pre><code class="language-kotlin">class BlockingQueue&lt;T&gt;(private val n: Int) {
    private val items = arrayOfNulls&lt;Any&gt;(n)
    private var head = 0
    private var tail = 0

    private val lock = ReentrantLock()
    private val notEmpty = lock.newCondition()
    private val notFull = lock.newCondition()
}

fun take(): T = lock.withLock {
    while (head == tail) notEmpty.await() // ждем
    val result = items[head] as T
    items[head] = null
    // ТУТ БАГ!
    if ((tail + 1) % n == head) notFull.signal() // была полна
    head = (head + 1) % n
    result // вернули из withLock
}

fun put(item: T): Unit = lock.withLock {
    while (true) { // пока не подходящее состояние
        val next = (tail + 1) % n
        if (next == head) { notFull.await(); continue }
        items[tail] = item
        // ТУТ БАГ!
        notEmpty.signal() // надо посылать один сигнал
        tail = next
        return@withLock
    }
}
</code></pre>
<p>Два сигнала от разных <code>take</code> могут сигнальнуть одному и тому же <code>put</code>. Нам не гарантировано, что сигнальнутый поток сразу проснется, поэтому он может проснуться после обоих сигналов и тогда другой <code>put</code> не проснется, а должен бы.</p>
<p>Простой способ починить: слать сигнал без условия. В худшем случае сигнал быстро отработает, т.к. будить некого.</p>
<p>Переключение контекста (разбудить поток) — очень дорого.</p>
<h2 id="interrupt"><a class="header" href="#interrupt">Interrupt</a></h2>
<p>У каждого потока есть флаг <code>interrupted</code>. Он выставляется методом <code>Thread.interrupt</code>, его проверяют методы <code>wait</code>/<code>await</code> и если он выставлен, то сбрасывают его и кидают <code>InterruptedException</code>. Таким образом можно кооперативно прекращать ожидание.</p>
<p>Если мы не знаем, что делать с <code>InterruptedException</code>, то надо писать так:</p>
<pre><code class="language-java">public T takeOrNull() {
    try {
        return take();
    } catch (InterruptedException e) {
        // перевыставим флаг interrupted
        Thread.currentThread().interrupt();
        return null;
    }
}
</code></pre>
<pre><code class="language-java">public class DoSomethingThread&lt;T&gt; extends Thread {
    private final BlockingQueue&lt;T&gt; queue; // задачи
    private volatile boolean closed; // флаг останова

    public void close() {
        closed = true; // ставим флаг останова (сначала!)
        interrupt(); // чтобы прервать ожидания
    }

    @Override
    public void run() {
        try {
            while (!closed) {
            T item = queue.take();
            doSomething(item);
            }
        } catch (InterruptedException e) {
            // а вот здесь можем проигнорировать -- уже выходим
        }
    }
}
</code></pre>
<h3 id="Обновляемое-значение"><a class="header" href="#Обновляемое-значение">Обновляемое значение</a></h3>
<p>Реализация с блокировкой:</p>
<pre><code class="language-kotlin">class DataHolder&lt;T&gt; {
    private var value: T? = null
    private val lock = ReentrantLock()

    fun update(item: T) = lock.withLock {
        value = item
    }

    fun remove(): T? = lock.withLock {
        value.also { value = null }
    }
}
</code></pre>
<p>Реализация с ожиданием:</p>
<pre><code class="language-kotlin">private val updated = lock.newCondition()

fun take(): T = lock.withLock {
    while (value == null) updated.await()
    value!!.also { value = null }
}

fun update(item: T) = lock.withLock {
    value = item
    updated.signal()
}
</code></pre>
<p>Реализация без блокировки, но не ждущими методами:</p>
<pre><code class="language-kotlin">class DataHolder&lt;T&gt; {
    private val v = atomic&lt;T?&gt;(null)

    fun update(item: T) {
        v.value = item // volatile write
    }

    fun remove(): T? {
        v.loop { cur -&gt;
            if (cur == null) return null
            if (v.compareAndSet(cur, null)) return cur
        }
    }
}
</code></pre>
<p>Ожидание без блокировки через <code>park</code>:</p>
<pre><code class="language-kotlin">class TakerThread&lt;T&gt; : Thread() {
// ...

    fun take(): T {
        assert(Thread.currentThread() == this)
        v.loop { cur -&gt;
            if (cur == null) {
                LockSupport.park()
                if (interrupted()) // ручная проверка флага
                    throw InterruptedException()
                return@loop // continue loop
            }
            if (v.compareAndSet(cur, null)) return cur
        }
    }
    
    fun update(item: T) {
        v.value = item // volatile write
        LockSupport.unpark(this)
    }
}
</code></pre>
<p>Поток будит только сам себя. Кроме того, <code>unpark</code> будит не только уже спящий поток, но и поток который уснет, т.е. <code>park</code> будет no-op.</p>
<p>Если мы хотим сделать ожидание из многих потоков, то надо использовать <code>AbstractQueuedSynchronizer</code>, правда он вообще-то предназначен для написания блокировок .</p>
<pre><code class="language-kotlin">inner class Sync : AbstractQueuedSynchronizer() {
    override fun tryAcquire(arg: Int): Boolean {
        val cur = v.value ?: return false
        if (!v.compareAndSet(cur, null)) return false
        // надо как-то вернуть значение отсюда, будем держать в поле
        results[arg] = cur
        return true
    }

    // всегда &quot;освобождаем&quot; -- будим следующего
    override fun tryRelease(arg: Int): Boolean = true
}

private val sync = Sync()

fun update(item: T) {
    v.value = item // volatile write
    sync.release(0) // шлем сигнал
}

fun take(): T {
    val arg = reserveResultsSlot() // приходится крутиться
    sync.acquireInterruptibly(arg) // ждет внутри
    // нужна перепроверка чтобы не потерять unpark
    if (v.value != null) sync.release(0)
    return releaseResultsSlot(arg)
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-72-Сложные-блокировки"><a class="header" href="#Лекция-72-Сложные-блокировки">Лекция 7.2. Сложные блокировки</a></h1>
<p>Мы раньше строили таблицу конфликтов для регистров, но мы можем так же делать и для своих структур. Например, для стека:</p>
<table><thead><tr><th></th><th><code>size</code></th><th><code>push</code></th><th><code>pop</code></th></tr></thead><tbody>
<tr><td><code>size</code></td><td></td><td>x</td><td>x</td></tr>
<tr><td><code>push</code></td><td>x</td><td>x</td><td>x</td></tr>
<tr><td><code>pop</code></td><td>x</td><td>x</td><td>x</td></tr>
</tbody></table>
<p>Если у нас грубая блокировка, то мы исключили <code>size</code>-<code>size</code>, но это не нужно. Чтобы не блокать то, что не нужно, придуманы read-write lock'и, которые имеют два режима: Read (Shared) и Write (Exclusive).</p>
<table><thead><tr><th></th><th>R</th><th>W</th></tr></thead><tbody>
<tr><td>R</td><td></td><td>x</td></tr>
<tr><td>W</td><td>x</td><td>x</td></tr>
</tbody></table>
<p>Пример:</p>
<pre><code class="language-kotlin">private val lock = ReentrantReadWriteLock()

val size: Int get() = lock.readLock().withLock {
    top
}

fun push(item: T) = lock.writeLock().withLock {
    data[top++] = item
}

fun pop(): T = lock.writeLock().withLock {
    data[--top]
}
</code></pre>
<p>Хотелось бы сделать что-то такое, но это deadlock потока с самим собой:</p>
<pre><code class="language-kotlin">val lock = ReentrantReadWriteLock()
lock.readLock().withLock {
    println(&quot;reading&quot;)
    lock.writeLock().withLock {
        println(&quot;writing&quot;)
    }
}
</code></pre>
<p>Казалось бы, можно придумать <code>UpgradableReadWriteLock</code> со следующей матрицей совместимости:</p>
<table><thead><tr><th></th><th>\(R_P\)</th><th>\(R_Q\)</th><th>\(W_P\)</th><th>\(W_Q\)</th></tr></thead><tbody>
<tr><td>\(R_P\)</td><td></td><td></td><td></td><td>x</td></tr>
<tr><td>\(R_Q\)</td><td></td><td></td><td>x</td><td></td></tr>
<tr><td>\(W_P\)</td><td></td><td>x</td><td></td><td>x</td></tr>
<tr><td>\(W_Q\)</td><td>x</td><td></td><td>x</td><td></td></tr>
</tbody></table>
<p>Однако если несколько потоков хотят <code>upgrade</code>нуться, то есть опасность deadlockа. Тогда создадим состояние &quot;Intent to write&quot;, которое будет эксклюзивным:</p>
<table><thead><tr><th></th><th>R</th><th>IW</th><th>W</th></tr></thead><tbody>
<tr><td>R</td><td></td><td></td><td>x</td></tr>
<tr><td>IW</td><td></td><td>x</td><td>x</td></tr>
<tr><td>W</td><td>x</td><td>x</td><td>x</td></tr>
</tbody></table>
<p>Напишем такой хитрый лок.</p>
<pre><code class="language-kotlin">private const val R_BIT = 1
private const val R_MASK = (1 shl 30) - 1
private const val IW_BIT = 1 shl 30
private const val W_BIT = 1 shl 31

class Sync : AbstractQueuedSynchronizer() {
    override fun tryAcquireShared(arg: Int): Int { // R или IW
        while (true) {
            val state = this.state
            if (state and W_BIT != 0) // если кто-то W, то нельзя
                return -1
            // если кто-то еще IW и мы хотим IW, то нельзя
            if (arg == IW_BIT &amp;&amp; state and IW_BIT != 0) 
                return -1
            val update = state + arg
            if (compareAndSetState(state, update))
                return 1
        }
    }
    
    override fun tryReleaseShared(arg: Int): Boolean {
        while (true) {
            val state = this.state
            val update = state - arg
            if (compareAndSetState(state, update))
                return update and (R_MASK or IW_BIT) == 0
        }
    }
    
    override fun tryAcquire(arg: Int): Boolean { // тривиально
        while (true) {
            val state = this.state
            if (state != 0)
                return false
            if (compareAndSetState(state, state or W_BIT))
                return true
        }
    }
    
    override fun tryRelease(arg: Int): Boolean {
        while (true) {
            val state = this.state
            val update = state and W_BIT.inv()
            if (compareAndSetState(state, update))
                return true
        }
    }
}
</code></pre>
<p>Ещё нужно в <code>ThreadLocal</code> состоянии держать сколько локов каждого типа мы держим, чтобы если мы держим лок, не брать его физически.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-8-Многопоточные-хеш-таблицы"><a class="header" href="#Лекция-8-Многопоточные-хеш-таблицы">Лекция 8. Многопоточные хеш-таблицы</a></h1>
<p>Мы будем использовать открытую адресацию ради локальности по кешу. </p>
<p>Без перестроения таблицы чтения тривиальны, но что делать когда мы перестраиваем таблицу? Будем читать из старого массива и атомарно менять ссылку на массив, когда перестроение закончено.</p>
<p><img src="img/cell.png" alt="" /></p>
<p>Когда мы перемещаем ячейку, мы помечаем её как перемещенную и запрещаем ее изменять.</p>
<p><img src="img/cell2.png" alt="" /></p>
<p>Для конкретных use case'ов можно оптимизировать нашу структуру.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Лекция-9-dual-data-structures"><a class="header" href="#Лекция-9-dual-data-structures">Лекция 9. Dual Data Structures</a></h1>
<p>Часто встречается паттерн producer-consumer, где n клиентов вбрасывают в пул задачи и m workerов их выполняют. Типичный способ коммуникации клиентов и workerов - synchronous queue:</p>
<pre><code class="language-kotlin">interface SynchronousQueue&lt;E&gt; {
    suspend fun send(element: E)
    suspend fun receive(): E
}
</code></pre>
<p>Как мы используем такую очередь?</p>
<p>Клиенты шлют задачи:</p>
<pre><code class="language-kotlin">val task = Task(...)
tasks.send(task)
</code></pre>
<p>Worker'ы получают задачи в бесконечном цикле:</p>
<pre><code class="language-kotlin">while (true) {
    val task = tasks.receive() // спим пока задач нет
    processTask(task)
}
</code></pre>
<p>Мы часто ложимся спать и просыпаемся, это медленно. Поэтому мы хотим использовать корутины — это легковесные потоки. В корутинах общение происходит через каналы, что более безопасно, чем общая память.</p>
<p>API корутин примерно такое:</p>
<pre><code class="language-kotlin">class Coroutine {
    var element: Any? // то что отправляем
    ...
}

fun curCroruntine(): Coroutine

suspend fun suspend(c: Coroutine)
fun resume(c: Coroutine)
</code></pre>
<p>Реализуем канал, пока что не думая про гонки:</p>
<pre><code class="language-kotlin">val senders = Queue&lt;Coroutine&gt;()
val receivers = Queue&lt;Coroutine&gt;()

suspend fun send(element: T) {
    if (receivers.isEmpty()) {
        val curCor = curCoroutine()
        curCor.element = element
        senders.enqueue(curCor)
        suspend(curCor)
    } else {
        val r = receivers.dequeue()
        r.element = element
        resume(r)
    }
}

suspend fun receive(): T {
    if (senders.isEmpty()) {
        val curCor = curCoroutine()
        receivers.enqueue(curCor)
        suspend(curCor)
        return curCor.element
    } else {
        val s = senders.dequeue()
        val res = s.element
        resume(s)
        return res
    }
}
</code></pre>
<p>В golang receive и send заворачиваются в грубую блокировку. Это не очень быстро. В java все быстрее за счет идеи, что: либо одна очередь пустая, либо другая, либо обе. Тогда будем держать только одну очередь (Майкла-Скотта), в которой храним пару (корутина, элемент (который надо отправить) (или некоторая константа если это <code>receive</code>)).</p>
<pre><code class="language-kotlin">fun send(x) {
    t := TAIL
    h := HEAD
    if (t == h || t.isSender()) {
        enqueueAndSuspend(t, x)
    } else {
        dequeAndResume(h)
    }
}
</code></pre>
<p>Это не линеаризуемо в силу засыпания, потому что операции ждут друг друга. Поэтому мы разбиваем <code>receive</code> на две части:</p>
<ul>
<li><code>request</code>, которая регистрирует поток как ждущий</li>
<li><code>follow-up</code>, которая работает после получения данных</li>
</ul>
<p>Тогда у нас есть линеаризуемость.</p>
<h3 id="faa-1"><a class="header" href="#faa-1">FAA</a></h3>
<p>Каналы похожи на очереди. Мы их можем ускорить с помощью <code>Fetch-and-add</code>, с двумя указателями.</p>
<pre><code class="language-kotlin">suspend fun send(x: T) {
    val s = FAA(&amp;sendIdx, +1)
    if s &lt; receiveIdx:
        // try to put f into w[s]
        // or resume the receiver
    else:
        // suspend in w[s]
}

suspend fun receive(): T {
    val r = FAA(&amp;receiveIdx, +1)
    if r &lt; sendIdx:
        // try to retrieve either
        // value or sender from w[r]
    else:
        // suspend in w[r]
}
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
    </body>
</html>
